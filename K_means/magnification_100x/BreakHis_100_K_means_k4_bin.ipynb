{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BreakHis_100_K_means_k4_bin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanjan02/BreakHis/blob/master/K_means/magnification_100x/BreakHis_100_K_means_k4_bin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lmT4qBChvZuK",
        "colab_type": "code",
        "outputId": "6800fd31-0363-496d-822b-b4b58863557f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.cluster import KMeans, estimate_bandwidth, MeanShift\n",
        "from glob import glob\n",
        "import cv2\n",
        "import fnmatch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sVnrj0Xvv-wn",
        "colab_type": "code",
        "outputId": "f6c36073-7b47-4ae2-e192-c7652bdd93a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KFOX2N8uwLIQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.load('/content/drive/My Drive/project/x_BreakHis_100_K_mean_K4.npy')\n",
        "y = np.load('/content/drive/My Drive/project/y_BreakHis_100_bin.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fV5FKFkww9Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 101)\n",
        "y_train = to_categorical(y_train, num_classes = 2)\n",
        "y_valid = to_categorical(y_valid, num_classes = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7R8coWBxBBm",
        "colab_type": "code",
        "outputId": "f7ceee17-7ff5-465e-9dd1-aed38043ba96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11927
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "input_tensor = Input(shape=(299,299,3))\n",
        "base_model = InceptionV3(input_tensor = input_tensor, include_top = False, pooling = 'average')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(2, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 149, 149, 32) 96          conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 149, 149, 32) 0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 147, 147, 32) 9216        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 147, 147, 32) 96          conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 147, 147, 32) 0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 147, 147, 64) 18432       activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 147, 147, 64) 192         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 147, 147, 64) 0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 73, 73, 64)   0           activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 73, 73, 80)   240         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 73, 73, 80)   0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 71, 71, 192)  138240      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 71, 71, 192)  576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 71, 71, 192)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 35, 35, 192)  0           activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 35, 35, 64)   192         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 35, 35, 64)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 35, 35, 96)   55296       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 35, 35, 48)   144         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 35, 35, 48)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 35, 35, 96)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 35, 35, 64)   76800       activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 35, 35, 96)   82944       activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 35, 35, 64)   192         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 35, 35, 96)   288         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 35, 35, 32)   96          conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 35, 35, 64)   0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 35, 35, 64)   0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 35, 35, 96)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 35, 35, 32)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_288[0][0]             \n",
            "                                                                 activation_290[0][0]             \n",
            "                                                                 activation_293[0][0]             \n",
            "                                                                 activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 35, 35, 64)   192         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 35, 35, 64)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 35, 35, 96)   55296       activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 35, 35, 48)   144         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 35, 35, 48)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 35, 35, 96)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 35, 35, 64)   76800       activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 35, 35, 96)   82944       activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 35, 35, 64)   192         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 35, 35, 96)   288         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 35, 35, 64)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 35, 35, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 35, 35, 96)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 35, 35, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_295[0][0]             \n",
            "                                                                 activation_297[0][0]             \n",
            "                                                                 activation_300[0][0]             \n",
            "                                                                 activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 35, 35, 64)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 35, 35, 48)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 35, 35, 64)   192         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 35, 35, 64)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 35, 35, 96)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 35, 35, 64)   0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_302[0][0]             \n",
            "                                                                 activation_304[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "                                                                 activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 35, 35, 64)   192         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 35, 35, 64)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 35, 35, 96)   55296       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 35, 35, 96)   288         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 35, 35, 96)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 17, 17, 96)   82944       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 17, 17, 384)  1152        conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 17, 17, 96)   288         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 17, 17, 384)  0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 17, 17, 96)   0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_309[0][0]             \n",
            "                                                                 activation_312[0][0]             \n",
            "                                                                 max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 17, 17, 128)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 17, 17, 128)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 17, 17, 128)  0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 17, 17, 128)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 17, 17, 128)  114688      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 17, 17, 128)  114688      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 17, 17, 128)  384         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 17, 17, 128)  0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 17, 17, 128)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 17, 17, 192)  172032      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 17, 17, 192)  172032      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 17, 17, 192)  576         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 17, 17, 192)  576         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 17, 17, 192)  0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 17, 17, 192)  0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 17, 17, 192)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_313[0][0]             \n",
            "                                                                 activation_316[0][0]             \n",
            "                                                                 activation_321[0][0]             \n",
            "                                                                 activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 17, 17, 160)  0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 17, 17, 160)  0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 17, 17, 160)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 17, 17, 160)  179200      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 17, 17, 160)  179200      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 17, 17, 160)  480         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 17, 17, 160)  0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 17, 17, 160)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 17, 17, 192)  215040      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 17, 17, 192)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 17, 17, 192)  0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 17, 17, 192)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_323[0][0]             \n",
            "                                                                 activation_326[0][0]             \n",
            "                                                                 activation_331[0][0]             \n",
            "                                                                 activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 17, 17, 160)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 17, 17, 160)  179200      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 17, 17, 160)  179200      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 17, 17, 160)  480         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 17, 17, 160)  480         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 17, 17, 160)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 17, 17, 160)  0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 17, 17, 192)  215040      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 17, 17, 192)  215040      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 17, 17, 192)  576         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 17, 17, 192)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 17, 17, 192)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 17, 17, 192)  0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_333[0][0]             \n",
            "                                                                 activation_336[0][0]             \n",
            "                                                                 activation_341[0][0]             \n",
            "                                                                 activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 17, 17, 192)  0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 17, 17, 192)  0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 17, 17, 192)  258048      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 17, 17, 192)  258048      activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 17, 17, 192)  0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_343[0][0]             \n",
            "                                                                 activation_346[0][0]             \n",
            "                                                                 activation_351[0][0]             \n",
            "                                                                 activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 17, 17, 192)  258048      activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 17, 17, 192)  0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 17, 17, 192)  258048      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 17, 17, 192)  576         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 17, 17, 192)  576         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 17, 17, 192)  0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 17, 17, 192)  0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 8, 8, 320)    552960      activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 192)    331776      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 8, 8, 320)    960         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 8, 8, 192)    576         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 8, 8, 320)    0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 8, 8, 192)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_354[0][0]             \n",
            "                                                                 activation_358[0][0]             \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 448)    1344        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 448)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 8, 8, 384)    1548288     activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 384)    1152        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 8, 8, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 8, 8, 384)    1152        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 8, 8, 384)    1152        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 8, 8, 384)    1152        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 8, 8, 384)    1152        conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 8, 8, 320)    960         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 8, 8, 384)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 8, 8, 384)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 8, 8, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 8, 8, 384)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 8, 8, 192)    576         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 8, 8, 320)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_361[0][0]             \n",
            "                                                                 activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 8, 8, 768)    0           activation_365[0][0]             \n",
            "                                                                 activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 8, 8, 192)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_359[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 8, 8, 448)    1344        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 8, 8, 448)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 8, 8, 384)    1548288     activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 8, 8, 384)    1152        conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 8, 8, 384)    1152        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 8, 8, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 8, 8, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 8, 8, 384)    1152        conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 8, 8, 384)    1152        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 8, 8, 384)    1152        conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 8, 8, 320)    960         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 8, 8, 384)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 8, 8, 384)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 8, 8, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 8, 8, 384)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 8, 8, 192)    576         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 8, 8, 320)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_370[0][0]             \n",
            "                                                                 activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 8, 8, 768)    0           activation_374[0][0]             \n",
            "                                                                 activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 8, 8, 192)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_368[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            2002        dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,853,786\n",
            "Trainable params: 23,819,354\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6i92962QDvbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "afXtmrA8Dvko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14c3cbONDvrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2m5lkUrXxAyl",
        "colab_type": "code",
        "outputId": "b2d56c8a-d2af-4b71-ca2c-f867a94dbe63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5134
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/project/model_check_path_BreakHis_100_bin_K_mean_k4_inception_v3',monitor=\"val_acc\", save_best_only=True, save_weights_only=False)\n",
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 150, verbose=1,  validation_data=(x_valid, y_valid), callbacks=[mcp])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4994 samples, validate on 1249 samples\n",
            "Epoch 1/150\n",
            "4994/4994 [==============================] - 221s 44ms/step - loss: 0.3154 - acc: 0.8751 - val_loss: 2.2500 - val_acc: 0.4788\n",
            "Epoch 2/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.2212 - acc: 0.9139 - val_loss: 4.5241 - val_acc: 0.3587\n",
            "Epoch 3/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.2158 - acc: 0.9119 - val_loss: 0.2672 - val_acc: 0.9135\n",
            "Epoch 4/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.1714 - acc: 0.9367 - val_loss: 0.5158 - val_acc: 0.8775\n",
            "Epoch 5/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0844 - acc: 0.9726 - val_loss: 0.2911 - val_acc: 0.9167\n",
            "Epoch 6/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0828 - acc: 0.9694 - val_loss: 0.3107 - val_acc: 0.8751\n",
            "Epoch 7/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0645 - acc: 0.9764 - val_loss: 0.2391 - val_acc: 0.9271\n",
            "Epoch 8/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.1000 - acc: 0.9624 - val_loss: 0.0610 - val_acc: 0.9824\n",
            "Epoch 9/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0379 - acc: 0.9852 - val_loss: 0.2500 - val_acc: 0.9287\n",
            "Epoch 10/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.1335 - acc: 0.9519 - val_loss: 0.2835 - val_acc: 0.9199\n",
            "Epoch 11/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0581 - acc: 0.9768 - val_loss: 0.1868 - val_acc: 0.9295\n",
            "Epoch 12/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0300 - acc: 0.9896 - val_loss: 0.0317 - val_acc: 0.9896\n",
            "Epoch 13/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0400 - acc: 0.9878 - val_loss: 0.2646 - val_acc: 0.9239\n",
            "Epoch 14/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0461 - acc: 0.9832 - val_loss: 0.2568 - val_acc: 0.9159\n",
            "Epoch 15/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0637 - acc: 0.9764 - val_loss: 0.1200 - val_acc: 0.9664\n",
            "Epoch 16/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0407 - acc: 0.9868 - val_loss: 0.2046 - val_acc: 0.9512\n",
            "Epoch 17/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0446 - acc: 0.9876 - val_loss: 0.0184 - val_acc: 0.9920\n",
            "Epoch 18/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0274 - acc: 0.9912 - val_loss: 0.2847 - val_acc: 0.9376\n",
            "Epoch 19/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0384 - acc: 0.9886 - val_loss: 0.0383 - val_acc: 0.9872\n",
            "Epoch 20/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0584 - acc: 0.9802 - val_loss: 0.3100 - val_acc: 0.8919\n",
            "Epoch 21/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0454 - acc: 0.9848 - val_loss: 0.3808 - val_acc: 0.9079\n",
            "Epoch 22/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0470 - acc: 0.9850 - val_loss: 0.4257 - val_acc: 0.9456\n",
            "Epoch 23/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0311 - acc: 0.9894 - val_loss: 0.6728 - val_acc: 0.7886\n",
            "Epoch 24/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0230 - val_acc: 0.9904\n",
            "Epoch 25/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 3.0576 - val_acc: 0.4948\n",
            "Epoch 26/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0588 - acc: 0.9766 - val_loss: 0.0422 - val_acc: 0.9848\n",
            "Epoch 27/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0124 - acc: 0.9956 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 28/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0193 - val_acc: 0.9928\n",
            "Epoch 29/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0130 - acc: 0.9948 - val_loss: 0.8024 - val_acc: 0.8751\n",
            "Epoch 30/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.1746 - val_acc: 0.9424\n",
            "Epoch 31/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.1669 - acc: 0.9361 - val_loss: 0.2246 - val_acc: 0.9616\n",
            "Epoch 32/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0353 - acc: 0.9858 - val_loss: 0.1273 - val_acc: 0.9632\n",
            "Epoch 33/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0213 - acc: 0.9940 - val_loss: 0.2809 - val_acc: 0.9247\n",
            "Epoch 34/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0203 - acc: 0.9940 - val_loss: 0.0306 - val_acc: 0.9896\n",
            "Epoch 35/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0567 - acc: 0.9798 - val_loss: 0.1993 - val_acc: 0.9544\n",
            "Epoch 36/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0319 - acc: 0.9916 - val_loss: 0.0125 - val_acc: 0.9960\n",
            "Epoch 37/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0612 - val_acc: 0.9784\n",
            "Epoch 38/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0976 - val_acc: 0.9744\n",
            "Epoch 39/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 1.3114 - val_acc: 0.7942\n",
            "Epoch 40/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0206 - val_acc: 0.9968\n",
            "Epoch 41/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0807 - acc: 0.9716 - val_loss: 1.5546 - val_acc: 0.7550\n",
            "Epoch 42/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0268 - val_acc: 0.9888\n",
            "Epoch 43/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0199 - acc: 0.9944 - val_loss: 0.0633 - val_acc: 0.9752\n",
            "Epoch 44/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9968\n",
            "Epoch 45/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 2.4570e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9968\n",
            "Epoch 46/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 2.2765e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9976\n",
            "Epoch 47/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0389 - acc: 0.9878 - val_loss: 3.1480 - val_acc: 0.6445\n",
            "Epoch 48/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0148 - acc: 0.9940 - val_loss: 0.0042 - val_acc: 0.9976\n",
            "Epoch 49/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.1530 - val_acc: 0.9311\n",
            "Epoch 50/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0138 - val_acc: 0.9952\n",
            "Epoch 51/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0173 - acc: 0.9936 - val_loss: 0.0777 - val_acc: 0.9744\n",
            "Epoch 52/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0068 - val_acc: 0.9984\n",
            "Epoch 53/150\n",
            "4994/4994 [==============================] - 199s 40ms/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 0.9896\n",
            "Epoch 54/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0401 - val_acc: 0.9888\n",
            "Epoch 55/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 56/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0758 - acc: 0.9788 - val_loss: 1.3593 - val_acc: 0.8094\n",
            "Epoch 57/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0691 - acc: 0.9784 - val_loss: 0.0423 - val_acc: 0.9904\n",
            "Epoch 58/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.0386 - val_acc: 0.9848\n",
            "Epoch 59/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.1389 - val_acc: 0.9576\n",
            "Epoch 60/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0109 - val_acc: 0.9944\n",
            "Epoch 61/150\n",
            "4994/4994 [==============================] - 198s 40ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.2232 - val_acc: 0.9560\n",
            "Epoch 62/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0119 - acc: 0.9954 - val_loss: 0.0572 - val_acc: 0.9808\n",
            "Epoch 63/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0593 - acc: 0.9822 - val_loss: 0.0255 - val_acc: 0.9904\n",
            "Epoch 64/150\n",
            "4994/4994 [==============================] - 197s 40ms/step - loss: 0.0485 - acc: 0.9832 - val_loss: 0.0508 - val_acc: 0.9832\n",
            "Epoch 65/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0046 - val_acc: 0.9984\n",
            "Epoch 66/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0128 - acc: 0.9966 - val_loss: 0.0673 - val_acc: 0.9760\n",
            "Epoch 67/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0429 - val_acc: 0.9960\n",
            "Epoch 68/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0325 - acc: 0.9932 - val_loss: 10.8013 - val_acc: 0.3275\n",
            "Epoch 69/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0311 - acc: 0.9890 - val_loss: 0.1346 - val_acc: 0.9792\n",
            "Epoch 70/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0807 - acc: 0.9750 - val_loss: 0.2679 - val_acc: 0.9039\n",
            "Epoch 71/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0315 - acc: 0.9892 - val_loss: 0.0496 - val_acc: 0.9792\n",
            "Epoch 72/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0485 - val_acc: 0.9936\n",
            "Epoch 73/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0132 - acc: 0.9974 - val_loss: 0.1074 - val_acc: 0.9728\n",
            "Epoch 74/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0431 - acc: 0.9854 - val_loss: 0.0418 - val_acc: 0.9904\n",
            "Epoch 75/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0252 - acc: 0.9930 - val_loss: 0.0231 - val_acc: 0.9960\n",
            "Epoch 76/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0169 - val_acc: 0.9976\n",
            "Epoch 77/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0147 - acc: 0.9970 - val_loss: 0.0841 - val_acc: 0.9696\n",
            "Epoch 78/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0184 - acc: 0.9948 - val_loss: 0.0064 - val_acc: 0.9968\n",
            "Epoch 79/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0365 - acc: 0.9890 - val_loss: 0.1338 - val_acc: 0.9616\n",
            "Epoch 80/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0027 - val_acc: 0.9992\n",
            "Epoch 81/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0038 - val_acc: 0.9984\n",
            "Epoch 82/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0232 - acc: 0.9932 - val_loss: 0.0141 - val_acc: 0.9944\n",
            "Epoch 83/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0574 - acc: 0.9826 - val_loss: 0.0322 - val_acc: 0.9872\n",
            "Epoch 84/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0297 - val_acc: 0.9936\n",
            "Epoch 85/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0458 - val_acc: 0.9808\n",
            "Epoch 86/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0441 - val_acc: 0.9896\n",
            "Epoch 87/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.1041 - val_acc: 0.9640\n",
            "Epoch 88/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0818 - acc: 0.9738 - val_loss: 0.0328 - val_acc: 0.9904\n",
            "Epoch 89/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0348 - acc: 0.9886 - val_loss: 0.0150 - val_acc: 0.9928\n",
            "Epoch 90/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0307 - acc: 0.9890 - val_loss: 0.0117 - val_acc: 0.9960\n",
            "Epoch 91/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0078 - val_acc: 0.9976\n",
            "Epoch 92/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0105 - val_acc: 0.9952\n",
            "Epoch 93/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0828 - acc: 0.9704 - val_loss: 0.0661 - val_acc: 0.9768\n",
            "Epoch 94/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0366 - acc: 0.9870 - val_loss: 0.0187 - val_acc: 0.9928\n",
            "Epoch 95/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 96/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0079 - val_acc: 0.9960\n",
            "Epoch 97/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0170 - acc: 0.9960 - val_loss: 0.0604 - val_acc: 0.9864\n",
            "Epoch 98/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0793 - acc: 0.9754 - val_loss: 0.0304 - val_acc: 0.9896\n",
            "Epoch 99/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0151 - acc: 0.9938 - val_loss: 0.0101 - val_acc: 0.9976\n",
            "Epoch 100/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0182 - val_acc: 0.9944\n",
            "Epoch 101/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0354 - acc: 0.9894 - val_loss: 0.0543 - val_acc: 0.9824\n",
            "Epoch 102/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0318 - acc: 0.9890 - val_loss: 0.0223 - val_acc: 0.9928\n",
            "Epoch 103/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0093 - val_acc: 0.9968\n",
            "Epoch 104/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0076 - val_acc: 0.9968\n",
            "Epoch 105/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0076 - val_acc: 0.9976\n",
            "Epoch 106/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0343 - acc: 0.9906 - val_loss: 0.0190 - val_acc: 0.9920\n",
            "Epoch 107/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.0995 - val_acc: 0.9712\n",
            "Epoch 108/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0496 - acc: 0.9846 - val_loss: 0.0766 - val_acc: 0.9752\n",
            "Epoch 109/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0336 - acc: 0.9874 - val_loss: 0.0114 - val_acc: 0.9952\n",
            "Epoch 110/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0050 - val_acc: 0.9992\n",
            "Epoch 111/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0049 - val_acc: 0.9992\n",
            "Epoch 112/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.0090 - val_acc: 0.9960\n",
            "Epoch 113/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0094 - val_acc: 0.9976\n",
            "Epoch 114/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0195 - val_acc: 0.9976\n",
            "Epoch 115/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0171 - val_acc: 0.9968\n",
            "Epoch 116/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0139 - val_acc: 0.9968\n",
            "Epoch 117/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0066 - val_acc: 0.9984\n",
            "Epoch 118/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0197 - acc: 0.9962 - val_loss: 0.2588 - val_acc: 0.9424\n",
            "Epoch 119/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0061 - acc: 0.9986 - val_loss: 0.0087 - val_acc: 0.9952\n",
            "Epoch 120/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 1.0105 - val_acc: 0.8631\n",
            "Epoch 121/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0357 - acc: 0.9900 - val_loss: 0.0342 - val_acc: 0.9864\n",
            "Epoch 122/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0494 - acc: 0.9862 - val_loss: 0.0169 - val_acc: 0.9920\n",
            "Epoch 123/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0045 - val_acc: 0.9976\n",
            "Epoch 124/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 9.1128e-04 - val_acc: 1.0000\n",
            "Epoch 125/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0421 - val_acc: 0.9856\n",
            "Epoch 126/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0654 - acc: 0.9798 - val_loss: 0.2502 - val_acc: 0.9055\n",
            "Epoch 127/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0600 - acc: 0.9814 - val_loss: 0.7880 - val_acc: 0.8415\n",
            "Epoch 128/150\n",
            "4994/4994 [==============================] - 197s 39ms/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.3135 - val_acc: 0.9271\n",
            "Epoch 129/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0265 - acc: 0.9924 - val_loss: 0.0192 - val_acc: 0.9928\n",
            "Epoch 130/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 131/150\n",
            "4994/4994 [==============================] - 196s 39ms/step - loss: 0.0044 - acc: 0.9982 - val_loss: 0.0105 - val_acc: 0.9968\n",
            "Epoch 132/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0163 - acc: 0.9944 - val_loss: 0.2011 - val_acc: 0.9408\n",
            "Epoch 133/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0034 - val_acc: 0.9984\n",
            "Epoch 134/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 5.3245e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9984\n",
            "Epoch 135/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0027 - val_acc: 0.9984\n",
            "Epoch 136/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0260 - acc: 0.9926 - val_loss: 0.1226 - val_acc: 0.9616\n",
            "Epoch 137/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.6160 - val_acc: 0.9111\n",
            "Epoch 138/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0331 - acc: 0.9884 - val_loss: 0.1351 - val_acc: 0.9736\n",
            "Epoch 139/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0118 - val_acc: 0.9960\n",
            "Epoch 140/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0806 - val_acc: 0.9784\n",
            "Epoch 141/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0919 - val_acc: 0.9768\n",
            "Epoch 142/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 0.0075 - val_acc: 0.9976\n",
            "Epoch 143/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 5.5273e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 144/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 7.5704e-04 - val_acc: 1.0000\n",
            "Epoch 145/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 6.3839e-04 - acc: 0.9998 - val_loss: 0.0130 - val_acc: 0.9936\n",
            "Epoch 146/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0065 - val_acc: 0.9984\n",
            "Epoch 147/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0397 - acc: 0.9878 - val_loss: 0.2276 - val_acc: 0.9760\n",
            "Epoch 148/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.4464 - val_acc: 0.9319\n",
            "Epoch 149/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.0317 - acc: 0.9924 - val_loss: 0.2225 - val_acc: 0.9632\n",
            "Epoch 150/150\n",
            "4994/4994 [==============================] - 195s 39ms/step - loss: 0.1329 - acc: 0.9581 - val_loss: 0.1828 - val_acc: 0.9656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sUNgjTAqkngx",
        "colab_type": "code",
        "outputId": "fd6b5a50-9a0a-4eba-ae82-7bfe337e1f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZBi8iYiITIbBm4iIyGT+P9TLxhy/HcsBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f344ea2ce48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8Lgcsm0Wk8Iy",
        "colab_type": "code",
        "outputId": "c4e4382c-9216-4c9c-9c35-0b74b5858c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f344e700eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bvM6p0vJlBwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/My Drive/project/model_check_path_BreakHis_100_bin_K_mean_k4_inception_v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ytdp9npalYnI",
        "colab_type": "code",
        "outputId": "d35d17f1-d88b-49e3-9efb-b3295ace194c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_valid)\n",
        "print(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       406\n",
            "           1       1.00      1.00      1.00       843\n",
            "\n",
            "   micro avg       1.00      1.00      1.00      1249\n",
            "   macro avg       1.00      1.00      1.00      1249\n",
            "weighted avg       1.00      1.00      1.00      1249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y1J5Wp-qlh37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.grid(b=False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhT7alq0lkC-",
        "colab_type": "code",
        "outputId": "96c1ac05-bccc-4d79-e1f0-9b438f04d3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['benign','malignant'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAG+CAYAAABRbDecAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f344e70f0b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LCbpotKo0xCZ",
        "colab_type": "code",
        "outputId": "0db9e434-b5c5-4910-d612-1f92ef0bb92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5598
        }
      },
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f38a5ee5860>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a5ee58d0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a5ee5be0>,\n",
              " <keras.layers.core.Activation at 0x7f38a5ee5f60>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a5efa668>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a0681048>,\n",
              " <keras.layers.core.Activation at 0x7f38a065fa90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a05fe7b8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a059b940>,\n",
              " <keras.layers.core.Activation at 0x7f38a05b8ef0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f38a04dda58>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a0531ef0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a043f240>,\n",
              " <keras.layers.core.Activation at 0x7f38a043fe48>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a03dbcc0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a03f16d8>,\n",
              " <keras.layers.core.Activation at 0x7f38a0393f60>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f38a030f978>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a00c7710>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a0087438>,\n",
              " <keras.layers.core.Activation at 0x7f388f7d1e80>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a02149e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f7972e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a0232cc0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f75a748>,\n",
              " <keras.layers.core.Activation at 0x7f38a01c7f28>,\n",
              " <keras.layers.core.Activation at 0x7f388f71c208>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388f5f90f0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a030f8d0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f38a0170c88>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f6999e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f5f9cc0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a0265c88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f38a0113ac8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f6b8b70>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f5555f8>,\n",
              " <keras.layers.core.Activation at 0x7f38a0265b38>,\n",
              " <keras.layers.core.Activation at 0x7f38a00cf668>,\n",
              " <keras.layers.core.Activation at 0x7f388f679240>,\n",
              " <keras.layers.core.Activation at 0x7f388f52ac18>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388f4f04a8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f22de80>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f1c19b0>,\n",
              " <keras.layers.core.Activation at 0x7f388f1e39b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f3ca9b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f15e2b0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f3e9c88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f125710>,\n",
              " <keras.layers.core.Activation at 0x7f388f37bef0>,\n",
              " <keras.layers.core.Activation at 0x7f388f0e43c8>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388ef42c88>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f4c8b00>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f328c50>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388f0629b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ef42ba8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f489630>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388f2cda90>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388efffb38>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ef1c320>,\n",
              " <keras.layers.core.Activation at 0x7f388f41dc18>,\n",
              " <keras.layers.core.Activation at 0x7f388f283ac8>,\n",
              " <keras.layers.core.Activation at 0x7f388ef95f98>,\n",
              " <keras.layers.core.Activation at 0x7f388eecf9e8>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388ee403c8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ebf9c88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388eb906a0>,\n",
              " <keras.layers.core.Activation at 0x7f388eb0de80>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ed979b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388eb2f860>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388edb8b70>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388eaf35f8>,\n",
              " <keras.layers.core.Activation at 0x7f388ecca898>,\n",
              " <keras.layers.core.Activation at 0x7f388eab5390>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388e912b70>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ee94a90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ecf5b38>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ea33898>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e912f28>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ee1a2e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ec9eac8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e9d0a20>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e8f2048>,\n",
              " <keras.layers.core.Activation at 0x7f388edd6f60>,\n",
              " <keras.layers.core.Activation at 0x7f388ec560b8>,\n",
              " <keras.layers.core.Activation at 0x7f388e963e80>,\n",
              " <keras.layers.core.Activation at 0x7f388e843ac8>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388e864518>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e7678d0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e706a58>,\n",
              " <keras.layers.core.Activation at 0x7f388e6c8710>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e69ceb8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e66ad68>,\n",
              " <keras.layers.core.Activation at 0x7f388e628be0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e864908>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e55fcf8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e823438>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e547f28>,\n",
              " <keras.layers.core.Activation at 0x7f388e7ed240>,\n",
              " <keras.layers.core.Activation at 0x7f388e5072e8>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f388e4fd8d0>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388e4fd828>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e113b38>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e0cd860>,\n",
              " <keras.layers.core.Activation at 0x7f388e08e518>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e0079e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e028b70>,\n",
              " <keras.layers.core.Activation at 0x7f388dfe8240>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e380ac8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388df6a0f0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e3a2da0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388df08a90>,\n",
              " <keras.layers.core.Activation at 0x7f388e337860>,\n",
              " <keras.layers.core.Activation at 0x7f388dec2be0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e299f28>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388de69e80>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e283e48>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388de7c9b0>,\n",
              " <keras.layers.core.Activation at 0x7f388e23f208>,\n",
              " <keras.layers.core.Activation at 0x7f388de209b0>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388dcf4588>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e4415f8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388e239940>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388dd9db00>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388dca0a58>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e3dae80>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388e1f9518>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388dd5e828>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388dc7d358>,\n",
              " <keras.layers.core.Activation at 0x7f388e3daf98>,\n",
              " <keras.layers.core.Activation at 0x7f388e19b6a0>,\n",
              " <keras.layers.core.Activation at 0x7f388dd222e8>,\n",
              " <keras.layers.core.Activation at 0x7f388dc3b588>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388dbb6d30>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d82ee80>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d7c19b0>,\n",
              " <keras.layers.core.Activation at 0x7f388d7e49b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d7622b0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d723710>,\n",
              " <keras.layers.core.Activation at 0x7f388d6e54a8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388dad6cf8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d6689b0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388da96828>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d603b38>,\n",
              " <keras.layers.core.Activation at 0x7f388daabef0>,\n",
              " <keras.layers.core.Activation at 0x7f388d597f98>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d9c69e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d545c88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d9ebb70>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d566ba8>,\n",
              " <keras.layers.core.Activation at 0x7f388d9aa240>,\n",
              " <keras.layers.core.Activation at 0x7f388d523ba8>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388d3faac8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388db9ffd0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d92c0f0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d447e10>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d3fa630>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388db59dd8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d8cba90>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d45b978>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d2ff2b0>,\n",
              " <keras.layers.core.Activation at 0x7f388e0efac8>,\n",
              " <keras.layers.core.Activation at 0x7f388d886be0>,\n",
              " <keras.layers.core.Activation at 0x7f388d47e978>,\n",
              " <keras.layers.core.Activation at 0x7f388d2d3d68>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388d281ac8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388cf1d0f0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388cf3da90>,\n",
              " <keras.layers.core.Activation at 0x7f388ce4cb70>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ce1cc88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ce306d8>,\n",
              " <keras.layers.core.Activation at 0x7f388cdd5e10>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d1de470>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388cd539e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d196438>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388cd16710>,\n",
              " <keras.layers.core.Activation at 0x7f388d172e80>,\n",
              " <keras.layers.core.Activation at 0x7f388ccd53c8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d1372e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388cc579b0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d0fb748>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388cc72b38>,\n",
              " <keras.layers.core.Activation at 0x7f388d09b940>,\n",
              " <keras.layers.core.Activation at 0x7f388cb87f98>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388cab8e10>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d2819b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388d03c9e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388cbb3c88>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ca894e0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388d261160>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388cfd9b70>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388cb55ba8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ca180f0>,\n",
              " <keras.layers.core.Activation at 0x7f388d232860>,\n",
              " <keras.layers.core.Activation at 0x7f388cf9a240>,\n",
              " <keras.layers.core.Activation at 0x7f388cb10320>,\n",
              " <keras.layers.core.Activation at 0x7f388ca4c940>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388c9eba58>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c62b9e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c5c8b70>,\n",
              " <keras.layers.core.Activation at 0x7f388c55cdd8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c50bb38>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c51ea58>,\n",
              " <keras.layers.core.Activation at 0x7f388c4eb9e8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c8ed2b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c40cc88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c890ac8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c4226a0>,\n",
              " <keras.layers.core.Activation at 0x7f388c81cba8>,\n",
              " <keras.layers.core.Activation at 0x7f388c3c2400>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c7ebcc0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c3409e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c78a710>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c304710>,\n",
              " <keras.layers.core.Activation at 0x7f388c7a9a90>,\n",
              " <keras.layers.core.Activation at 0x7f388c2c74a8>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388c19fc88>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c9ebcc0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c727a20>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c2459b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c19fba8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c96f048>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c6ec748>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c263b38>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388c17dba8>,\n",
              " <keras.layers.core.Activation at 0x7f388c8c0f60>,\n",
              " <keras.layers.core.Activation at 0x7f388c6af400>,\n",
              " <keras.layers.core.Activation at 0x7f388c1f5f98>,\n",
              " <keras.layers.core.Activation at 0x7f388c0d5c50>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388c0a73c8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bede0f0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388be82a90>,\n",
              " <keras.layers.core.Activation at 0x7f388be0fba8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bddfc88>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bdf6710>,\n",
              " <keras.layers.core.Activation at 0x7f388bd97400>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388c0faa90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bd159e8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bfff160>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bcda710>,\n",
              " <keras.layers.core.Activation at 0x7f388c014fd0>,\n",
              " <keras.layers.core.Activation at 0x7f388bc9b3c8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bffe9b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bc199b0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bf9db70>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bc36b38>,\n",
              " <keras.layers.core.Activation at 0x7f388bf5e240>,\n",
              " <keras.layers.core.Activation at 0x7f388bb4af98>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f388bb7bc88>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388bb7bba8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b78e550>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b775fd0>,\n",
              " <keras.layers.core.Activation at 0x7f388b775d30>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ba4ea90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b692518>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ba12748>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b6b06a0>,\n",
              " <keras.layers.core.Activation at 0x7f388b9d6400>,\n",
              " <keras.layers.core.Activation at 0x7f388b673438>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b9538d0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b8b5ba8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b5f3940>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b4d2c18>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388b42d978>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388bb1aba8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b972a58>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b84aa58>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b592ac8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b4e7b38>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b42da90>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388bad2320>,\n",
              " <keras.layers.core.Activation at 0x7f388b889eb8>,\n",
              " <keras.layers.core.Activation at 0x7f388b7eaa20>,\n",
              " <keras.layers.core.Activation at 0x7f388b528f28>,\n",
              " <keras.layers.core.Activation at 0x7f388b406a90>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b38aef0>,\n",
              " <keras.layers.core.Activation at 0x7f388ba4ea58>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388b74fcf8>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388b3e9d68>,\n",
              " <keras.layers.core.Activation at 0x7f388b38a978>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388b30c9b0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388af9ccf8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ae81cf8>,\n",
              " <keras.layers.core.Activation at 0x7f388af2c710>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b1cae48>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388aeae0b8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b22fda0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ae51ba8>,\n",
              " <keras.layers.core.Activation at 0x7f388b144c18>,\n",
              " <keras.layers.core.Activation at 0x7f388ae0da90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b10acf8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b048a58>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388adb0e10>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ace5ac8>,\n",
              " <keras.layers.pooling.AveragePooling2D at 0x7f388ac3ed68>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388b32d5c0>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b128780>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b00b780>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ad44978>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388acac7f0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f388ab85358>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388b292668>,\n",
              " <keras.layers.core.Activation at 0x7f388b0ca470>,\n",
              " <keras.layers.core.Activation at 0x7f388afcb438>,\n",
              " <keras.layers.core.Activation at 0x7f388ad67978>,\n",
              " <keras.layers.core.Activation at 0x7f388ac6e4a8>,\n",
              " <keras.layers.normalization.BatchNormalization at 0x7f388ab1dda0>,\n",
              " <keras.layers.core.Activation at 0x7f388b262f28>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388af4d908>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388abe9978>,\n",
              " <keras.layers.core.Activation at 0x7f388ab1df60>,\n",
              " <keras.layers.merge.Concatenate at 0x7f388aaeac50>,\n",
              " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f388aa812e8>,\n",
              " <keras.layers.core.Dense at 0x7f38a5ee5b00>,\n",
              " <keras.layers.core.Dense at 0x7f388aaa2f28>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "RK8OhDlx8aAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "from keras.layers import Input\n",
        "from keras import activations\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import initializers\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "\n",
        "import h5py as h5py\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "from vis.visualization import visualize_activation,visualize_saliency,overlay,visualize_cam\n",
        "from vis.utils import utils\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0G9RVlyzwjP",
        "colab_type": "code",
        "outputId": "b7017f1e-7b1a-44b9-b5fd-6d9d6ed6b2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "from vis.visualization import visualize_cam\n",
        "from vis.utils import utils\n",
        "from keras import activations\n",
        "layer_idx = utils.find_layer_idx(model, 'dense_6')\n",
        "print(\"Remove Activation from Last Layer\")\n",
        "# Swap softmax with linear\n",
        "model.layers[layer_idx].activation = activations.linear\n",
        "print(\"Done. Now Applying changes to the model ...\")\n",
        "model = utils.apply_modifications(model)\n",
        "#visualize_cam(model, Dense_2,seed_input = x_valid[-1], filter_indices=[22])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove Activation from Last Layer\n",
            "Done. Now Applying changes to the model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8KvxVNF5uR9",
        "colab_type": "code",
        "outputId": "2b8875fe-3c8e-4b95-d0b1-c6c75b5c5972",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "im_file = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a269cacf-48bc-498f-9a83-b978cf1c434a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a269cacf-48bc-498f-9a83-b978cf1c434a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SOB_M_DC-14-2985-100-001.png to SOB_M_DC-14-2985-100-001.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SMSEIv0k6OOR",
        "colab_type": "code",
        "outputId": "dd7d22a7-3b56-4726-9554-3eb8a900f35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1858
        }
      },
      "cell_type": "code",
      "source": [
        "im_file=\"husky.jpg\"\n",
        "\n",
        "img1 = x_valid[7]\n",
        "img1 = np.expand_dims(img1, axis=0)\n",
        "img1 = preprocess_input(img1)\n",
        "layer_idx = utils.find_layer_idx(model, 'dense_6')\n",
        "heatmap = visualize_cam(model, layer_idx, filter_indices=248, seed_input=img1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 248 of dimension 1 out of bounds. for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [?,2], [2], [2], [2] and with computed input tensors: input[1] = <0 248>, input[2] = <0 249>, input[3] = <1 1>.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-48a5b2382f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_layer_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dense_6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m248\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam\u001b[0;34m(model, layer_idx, filter_indices, seed_input, penultimate_layer_idx, backprop_modifier, grad_modifier)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mActivationMaximization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     ]\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvisualize_cam_with_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam_with_losses\u001b[0;34m(input_tensor, losses, seed_input, penultimate_layer, grad_modifier)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m    158\u001b[0m     \u001b[0mpenultimate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrt_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenultimate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_grads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_output_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_modifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_tensor, losses, input_range, wrt_tensor, norm_grads)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Perf optimization. Don't build loss function with 0 weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0moverall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/losses.py\u001b[0m in \u001b[0;36mbuild_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;31m# slicer is used to deal with `channels_first` or `channels_last` image data formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8520\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8521\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8522\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8523\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8524\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: slice index 248 of dimension 1 out of bounds. for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [?,2], [2], [2], [2] and with computed input tensors: input[1] = <0 248>, input[2] = <0 249>, input[3] = <1 1>."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bBEZWCLcD592",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize_class_activation_map():\n",
        "\n",
        "        #Reshape to the network input shape (3, w, h).\n",
        "        img = np.array([np.transpose(np.float32(x_valid[7]), (2, 0, 1))])\n",
        "        \n",
        "        #Get the 512 input weights to the softmax.\n",
        "        class_weights = model.layers[-1].get_weights()[0]\n",
        "        final_conv_layer = get_output_layer(model, \"global_average_pooling2d_4\")\n",
        "        get_output = K.function([model.layers[0].input], \\\n",
        "                    [final_conv_layer.output, \n",
        "        model.layers[-1].output])\n",
        "        [conv_outputs, predictions] = get_output([img])\n",
        "        conv_outputs = conv_outputs[0, :, :, :]\n",
        "\n",
        "        #Create the class activation map.\n",
        "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
        "        target_class = 1\n",
        "        for i, w in enumerate(class_weights[:, target_class]):\n",
        "                cam += w * conv_outputs[i, :, :]\n",
        "        return cam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GyEq6z9Eapc",
        "colab_type": "code",
        "outputId": "5772d93a-7943-45b7-e78a-6adf91084cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(visualize_class_activation_map())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-05dc9d704b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize_class_activation_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-79cf96e36e69>\u001b[0m in \u001b[0;36mvisualize_class_activation_map\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#Get the 512 input weights to the softmax.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfinal_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_output_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"global_average_pooling2d_4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         get_output = K.function([model.layers[0].input],                     [final_conv_layer.output, \n\u001b[1;32m     10\u001b[0m         model.layers[-1].output])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_output_layer' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vrUtbkyHHJG8",
        "colab_type": "code",
        "outputId": "4be627e3-9fe4-4ff8-b6ef-6b7da091e4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1272
        }
      },
      "cell_type": "code",
      "source": [
        "heat_map = visualize_cam(model, utils.find_layer_idx(model, 'dense_8'), y_valid[7], x_valid[7])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-0fb4a42a5869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_layer_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dense_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam\u001b[0;34m(model, layer_idx, filter_indices, seed_input, penultimate_layer_idx, backprop_modifier, grad_modifier)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mActivationMaximization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     ]\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvisualize_cam_with_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam_with_losses\u001b[0;34m(input_tensor, losses, seed_input, penultimate_layer, grad_modifier)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m    158\u001b[0m     \u001b[0mpenultimate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrt_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenultimate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_grads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_output_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_modifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_tensor, losses, input_range, wrt_tensor, norm_grads)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Perf optimization. Don't build loss function with 0 weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0moverall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/losses.py\u001b[0m in \u001b[0;36mbuild_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;31m# slicer is used to deal with `channels_first` or `channels_last` image data formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8520\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8521\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8522\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8523\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8524\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'begin' has DataType float32 not in list of allowed values: int32, int64"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mFN6rN-tKTm1",
        "colab_type": "code",
        "outputId": "bb88fa9c-52df-4a62-ef90-615666e31466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "output = model.output[:, argmax]\n",
        "last_conv_layer = model.get_layer('global_average_pooling2d_4')\n",
        "grads = K.gradients(output, last_conv_layer.output)[0]\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "pooled_grad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-5a49900e39ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'global_average_pooling2d_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpooled_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'argmax' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "n8uDGBEeL_Ia",
        "colab_type": "code",
        "outputId": "9b76f76a-d087-448e-b936-e0bbf58adb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1823
        }
      },
      "cell_type": "code",
      "source": [
        "visuaheat_map = visualize_cam(model, utils.find_layer_idx(model, 'dense_8'), filter_indices=[22],seed_input=x_valid[1],penultimate_layer_idx=utils.find_layer_idx(model, 'global_average_pooling2d_4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 22 of dimension 1 out of bounds. for 'strided_slice_5' (op: 'StridedSlice') with input shapes: [?,2], [2], [2], [2] and with computed input tensors: input[1] = <0 22>, input[2] = <0 23>, input[3] = <1 1>.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-9554f233fcb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisuaheat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_layer_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dense_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpenultimate_layer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_layer_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'global_average_pooling2d_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam\u001b[0;34m(model, layer_idx, filter_indices, seed_input, penultimate_layer_idx, backprop_modifier, grad_modifier)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mActivationMaximization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     ]\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvisualize_cam_with_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/visualization/saliency.py\u001b[0m in \u001b[0;36mvisualize_cam_with_losses\u001b[0;34m(input_tensor, losses, seed_input, penultimate_layer, grad_modifier)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m    158\u001b[0m     \u001b[0mpenultimate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenultimate_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrt_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenultimate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_grads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenultimate_output_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_modifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_modifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_tensor, losses, input_range, wrt_tensor, norm_grads)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Perf optimization. Don't build loss function with 0 weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0moverall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moverall_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vis/losses.py\u001b[0m in \u001b[0;36mbuild_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;31m# slicer is used to deal with `channels_first` or `channels_last` image data formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8520\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8521\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8522\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8523\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8524\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: slice index 22 of dimension 1 out of bounds. for 'strided_slice_5' (op: 'StridedSlice') with input shapes: [?,2], [2], [2], [2] and with computed input tensors: input[1] = <0 22>, input[2] = <0 23>, input[3] = <1 1>."
          ]
        }
      ]
    }
  ]
}