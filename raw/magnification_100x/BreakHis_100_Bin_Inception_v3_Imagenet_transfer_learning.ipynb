{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BreakHis_100_Bin_Inception_v3_Imagenet_transfer_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanjan02/BreakHis/blob/master/raw/magnification_100x/BreakHis_100_Bin_Inception_v3_Imagenet_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MX6V-0Jxo-pG",
        "colab_type": "code",
        "outputId": "2882257a-8756-493e-ad12-557692061baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.cluster import KMeans, estimate_bandwidth, MeanShift\n",
        "from glob import glob\n",
        "import cv2\n",
        "import fnmatch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7XCv6cMpMXy",
        "colab_type": "code",
        "outputId": "bac5698e-7e9d-43b2-a4b2-506239ef7d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cJvpoMaCpSO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.load('/content/drive/My Drive/project/x_BreakHis_40.npy')\n",
        "y = np.load('/content/drive/My Drive/project/y_BreakHis_40_bin.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQOjHyFCpZ4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 101)\n",
        "y_train = to_categorical(y_train, num_classes = 2)\n",
        "y_valid = to_categorical(y_valid, num_classes = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zy4tas3npbHd",
        "colab_type": "code",
        "outputId": "45a2a522-3b9a-4d28-845a-8580d661ca03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11407
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, LSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "input_tensor = Input(shape=(299,299,3))\n",
        "base_model = InceptionV3(input_tensor = input_tensor, include_top = False, pooling = 'average', weights = 'imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation = 'relu')(x)\n",
        "x = Dense(2, activation = 'softmax')(x)\n",
        "model = Model(base_model.input,x)\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 149, 149, 32) 96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 149, 149, 32) 0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 147, 147, 32) 9216        activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 147, 147, 32) 96          conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 147, 147, 32) 0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 147, 147, 64) 18432       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 147, 147, 64) 192         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 147, 147, 64) 0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 73, 73, 80)   240         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 73, 73, 80)   0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 71, 71, 192)  138240      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 71, 71, 192)  576         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 71, 71, 192)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 35, 35, 192)  0           activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 35, 35, 64)   192         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 35, 35, 64)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 35, 35, 96)   55296       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 35, 35, 48)   144         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 35, 35, 48)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 35, 35, 64)   76800       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 35, 35, 96)   82944       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 35, 35, 64)   192         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 35, 35, 96)   288         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 35, 35, 32)   96          conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 35, 35, 64)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 35, 35, 96)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 35, 35, 32)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_194[0][0]             \n",
            "                                                                 activation_196[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "                                                                 activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 35, 35, 64)   192         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 35, 35, 64)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 35, 35, 96)   55296       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 35, 35, 48)   144         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 35, 35, 48)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 35, 35, 64)   76800       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 35, 35, 96)   82944       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 35, 35, 64)   192         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 35, 35, 96)   288         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 35, 35, 64)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 35, 35, 96)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_201[0][0]             \n",
            "                                                                 activation_203[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "                                                                 activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 35, 35, 64)   192         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 35, 35, 64)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 35, 35, 96)   55296       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 35, 35, 48)   144         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 35, 35, 48)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 35, 35, 64)   76800       activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 35, 35, 96)   82944       activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 35, 35, 64)   192         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 35, 35, 96)   288         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 35, 35, 64)   192         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 35, 35, 64)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 35, 35, 96)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 35, 35, 64)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_208[0][0]             \n",
            "                                                                 activation_210[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "                                                                 activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 35, 35, 64)   192         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 35, 35, 64)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 35, 35, 96)   55296       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 35, 35, 96)   288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 35, 35, 96)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 17, 17, 96)   82944       activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 17, 17, 384)  1152        conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 17, 17, 96)   288         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 17, 17, 384)  0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 17, 17, 96)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_215[0][0]             \n",
            "                                                                 activation_218[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 17, 17, 128)  114688      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 17, 17, 128)  114688      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 17, 17, 128)  384         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 17, 17, 128)  384         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 17, 17, 128)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 17, 17, 128)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 17, 17, 192)  172032      activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 17, 17, 192)  172032      activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 17, 17, 192)  576         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 17, 17, 192)  576         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 17, 17, 192)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 17, 17, 192)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_219[0][0]             \n",
            "                                                                 activation_222[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "                                                                 activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 17, 17, 160)  179200      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 17, 17, 160)  179200      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 17, 17, 160)  480         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 17, 17, 160)  480         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 17, 17, 160)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 17, 17, 160)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 17, 17, 192)  215040      activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 17, 17, 192)  215040      activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 17, 17, 192)  576         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 17, 17, 192)  576         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 17, 17, 192)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 17, 17, 192)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_229[0][0]             \n",
            "                                                                 activation_232[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "                                                                 activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 17, 17, 160)  179200      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 17, 17, 160)  179200      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 17, 17, 160)  480         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 17, 17, 160)  480         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 17, 17, 160)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 17, 17, 160)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 17, 17, 192)  215040      activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 17, 17, 192)  215040      activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 17, 17, 192)  576         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 17, 17, 192)  576         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 17, 17, 192)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 17, 17, 192)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_239[0][0]             \n",
            "                                                                 activation_242[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "                                                                 activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 17, 17, 192)  258048      activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 17, 17, 192)  258048      activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_249[0][0]             \n",
            "                                                                 activation_252[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "                                                                 activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 17, 17, 192)  258048      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 17, 17, 192)  576         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 17, 17, 192)  576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 17, 17, 192)  0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 17, 17, 192)  0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 8, 8, 320)    552960      activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 192)    331776      activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 8, 8, 320)    960         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 8, 8, 192)    576         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 8, 8, 320)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 8, 8, 192)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_260[0][0]             \n",
            "                                                                 activation_264[0][0]             \n",
            "                                                                 max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 448)    1344        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 8, 8, 448)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 384)    1548288     activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 384)    442368      activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 384)    442368      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 384)    1152        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 384)    1152        conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 320)    960         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 8, 8, 384)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 384)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 192)    576         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 8, 8, 320)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_267[0][0]             \n",
            "                                                                 activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_271[0][0]             \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 192)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_265[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 448)    1344        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 448)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 384)    1548288     activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 384)    442368      activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 384)    442368      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_27 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 384)    1152        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 384)    1152        conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 320)    960         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 384)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 384)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 8, 8, 192)    576         conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 320)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_276[0][0]             \n",
            "                                                                 activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 8, 768)    0           activation_280[0][0]             \n",
            "                                                                 activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 8, 8, 192)    0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_274[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_6[0][0]              \n",
            "                                                                 activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2)            2002        dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,853,786\n",
            "Trainable params: 2,051,002\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dJpr4VSopyQr",
        "colab_type": "code",
        "outputId": "cf7b15a5-7af9-419a-f796-1959528fa572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5134
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/project/model_check_path_BreakHis_40_bin_K_inception_v3_imagenet_transfer_learning',monitor=\"val_acc\", save_best_only=True, save_weights_only=False)\n",
        "hist = model.fit(x_train,y_train,batch_size = 32, epochs = 150, verbose=1,  validation_data=(x_valid, y_valid), callbacks=[mcp])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4788 samples, validate on 1197 samples\n",
            "Epoch 1/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0164 - acc: 0.9946 - val_loss: 5.1170 - val_acc: 0.6800\n",
            "Epoch 2/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0265 - acc: 0.9910 - val_loss: 5.0763 - val_acc: 0.6834\n",
            "Epoch 3/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 4.9972 - val_acc: 0.6876\n",
            "Epoch 4/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0200 - acc: 0.9927 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 5/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0135 - acc: 0.9962 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 6/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0092 - acc: 0.9967 - val_loss: 5.0175 - val_acc: 0.6884\n",
            "Epoch 7/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 8/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0140 - acc: 0.9969 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 9/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0110 - acc: 0.9960 - val_loss: 5.0128 - val_acc: 0.6876\n",
            "Epoch 10/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0112 - acc: 0.9958 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 11/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0114 - acc: 0.9956 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 12/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 4.9843 - val_acc: 0.6901\n",
            "Epoch 13/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0107 - acc: 0.9971 - val_loss: 5.0725 - val_acc: 0.6834\n",
            "Epoch 14/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0150 - acc: 0.9954 - val_loss: 5.0361 - val_acc: 0.6859\n",
            "Epoch 15/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 16/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0151 - acc: 0.9942 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 17/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0140 - acc: 0.9946 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 18/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 19/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 5.0053 - val_acc: 0.6884\n",
            "Epoch 20/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0091 - acc: 0.9960 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 21/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 5.0146 - val_acc: 0.6884\n",
            "Epoch 22/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0314 - acc: 0.9908 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 23/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0062 - acc: 0.9973 - val_loss: 5.0902 - val_acc: 0.6817\n",
            "Epoch 24/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 25/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 26/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 27/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0127 - acc: 0.9952 - val_loss: 5.0142 - val_acc: 0.6884\n",
            "Epoch 28/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 5.0192 - val_acc: 0.6884\n",
            "Epoch 29/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 5.0317 - val_acc: 0.6867\n",
            "Epoch 30/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0147 - acc: 0.9937 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 31/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 5.0136 - val_acc: 0.6884\n",
            "Epoch 32/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 33/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 34/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 35/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 36/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0167 - acc: 0.9952 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 37/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 4.9822 - val_acc: 0.6909\n",
            "Epoch 38/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0121 - acc: 0.9962 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 39/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0247 - acc: 0.9908 - val_loss: 5.0342 - val_acc: 0.6867\n",
            "Epoch 40/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 5.0697 - val_acc: 0.6834\n",
            "Epoch 41/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0159 - acc: 0.9939 - val_loss: 5.0345 - val_acc: 0.6876\n",
            "Epoch 42/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0119 - acc: 0.9952 - val_loss: 5.0422 - val_acc: 0.6867\n",
            "Epoch 43/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 5.0602 - val_acc: 0.6850\n",
            "Epoch 44/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0087 - acc: 0.9969 - val_loss: 4.9959 - val_acc: 0.6901\n",
            "Epoch 45/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 5.0017 - val_acc: 0.6884\n",
            "Epoch 46/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 47/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0180 - acc: 0.9942 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 48/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0075 - acc: 0.9971 - val_loss: 4.9946 - val_acc: 0.6892\n",
            "Epoch 49/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 50/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 51/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 5.0142 - val_acc: 0.6884\n",
            "Epoch 52/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0206 - acc: 0.9929 - val_loss: 5.0070 - val_acc: 0.6892\n",
            "Epoch 53/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 54/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 4.9985 - val_acc: 0.6884\n",
            "Epoch 55/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0045 - acc: 0.9979 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 56/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0101 - acc: 0.9962 - val_loss: 5.0324 - val_acc: 0.6876\n",
            "Epoch 57/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0164 - acc: 0.9952 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 58/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0231 - acc: 0.9931 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 59/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0083 - acc: 0.9981 - val_loss: 5.0021 - val_acc: 0.6884\n",
            "Epoch 60/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 61/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0146 - acc: 0.9960 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 62/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 4.9881 - val_acc: 0.6901\n",
            "Epoch 63/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 5.1383 - val_acc: 0.6792\n",
            "Epoch 64/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 5.0147 - val_acc: 0.6876\n",
            "Epoch 65/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0100 - acc: 0.9964 - val_loss: 5.0458 - val_acc: 0.6859\n",
            "Epoch 66/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0113 - acc: 0.9960 - val_loss: 5.0009 - val_acc: 0.6892\n",
            "Epoch 67/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0109 - acc: 0.9956 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 68/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0074 - acc: 0.9975 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 69/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0152 - acc: 0.9946 - val_loss: 4.9988 - val_acc: 0.6884\n",
            "Epoch 70/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0301 - acc: 0.9916 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 71/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 5.0534 - val_acc: 0.6859\n",
            "Epoch 72/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0058 - acc: 0.9979 - val_loss: 4.9957 - val_acc: 0.6901\n",
            "Epoch 73/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 5.2774 - val_acc: 0.6692\n",
            "Epoch 74/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0138 - acc: 0.9958 - val_loss: 5.0230 - val_acc: 0.6884\n",
            "Epoch 75/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 5.0255 - val_acc: 0.6867\n",
            "Epoch 76/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 4.9997 - val_acc: 0.6884\n",
            "Epoch 77/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 5.0439 - val_acc: 0.6867\n",
            "Epoch 78/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 5.0179 - val_acc: 0.6876\n",
            "Epoch 79/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 5.0645 - val_acc: 0.6850\n",
            "Epoch 80/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0104 - acc: 0.9962 - val_loss: 4.9801 - val_acc: 0.6892\n",
            "Epoch 81/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0110 - acc: 0.9956 - val_loss: 4.9177 - val_acc: 0.6942\n",
            "Epoch 82/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 5.0167 - val_acc: 0.6884\n",
            "Epoch 83/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 84/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0056 - acc: 0.9977 - val_loss: 5.0029 - val_acc: 0.6892\n",
            "Epoch 85/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0098 - acc: 0.9958 - val_loss: 5.0650 - val_acc: 0.6842\n",
            "Epoch 86/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 5.0233 - val_acc: 0.6859\n",
            "Epoch 87/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0037 - acc: 0.9985 - val_loss: 5.0191 - val_acc: 0.6850\n",
            "Epoch 88/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 5.0328 - val_acc: 0.6859\n",
            "Epoch 89/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0226 - acc: 0.9925 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 90/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0092 - acc: 0.9960 - val_loss: 5.0229 - val_acc: 0.6884\n",
            "Epoch 91/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 5.0545 - val_acc: 0.6859\n",
            "Epoch 92/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 93/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 5.0390 - val_acc: 0.6867\n",
            "Epoch 94/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 5.0092 - val_acc: 0.6892\n",
            "Epoch 95/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0061 - acc: 0.9975 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 96/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 4.9999 - val_acc: 0.6892\n",
            "Epoch 97/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 5.0361 - val_acc: 0.6876\n",
            "Epoch 98/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 5.0376 - val_acc: 0.6859\n",
            "Epoch 99/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 5.0630 - val_acc: 0.6859\n",
            "Epoch 100/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0054 - acc: 0.9979 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 101/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 5.0402 - val_acc: 0.6867\n",
            "Epoch 102/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0085 - acc: 0.9969 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 103/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 104/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0195 - acc: 0.9929 - val_loss: 5.0371 - val_acc: 0.6867\n",
            "Epoch 105/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 5.0226 - val_acc: 0.6884\n",
            "Epoch 106/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0050 - acc: 0.9977 - val_loss: 5.0229 - val_acc: 0.6884\n",
            "Epoch 107/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0118 - acc: 0.9960 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 108/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 5.0409 - val_acc: 0.6859\n",
            "Epoch 109/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0059 - acc: 0.9971 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 110/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0170 - acc: 0.9952 - val_loss: 5.0292 - val_acc: 0.6850\n",
            "Epoch 111/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0049 - acc: 0.9975 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 112/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 5.0515 - val_acc: 0.6859\n",
            "Epoch 113/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 114/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 5.0168 - val_acc: 0.6876\n",
            "Epoch 115/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 116/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0132 - acc: 0.9962 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 117/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0037 - acc: 0.9983 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 118/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0043 - acc: 0.9979 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 119/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 120/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0069 - acc: 0.9975 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 121/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 122/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 5.0464 - val_acc: 0.6867\n",
            "Epoch 123/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0117 - acc: 0.9948 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 124/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 5.0279 - val_acc: 0.6876\n",
            "Epoch 125/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0058 - acc: 0.9973 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 126/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 127/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 128/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 129/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0126 - acc: 0.9958 - val_loss: 5.0091 - val_acc: 0.6892\n",
            "Epoch 130/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0116 - acc: 0.9954 - val_loss: 4.9952 - val_acc: 0.6884\n",
            "Epoch 131/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 5.0416 - val_acc: 0.6850\n",
            "Epoch 132/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 5.0210 - val_acc: 0.6867\n",
            "Epoch 133/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0082 - acc: 0.9971 - val_loss: 5.0348 - val_acc: 0.6850\n",
            "Epoch 134/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0040 - acc: 0.9985 - val_loss: 5.0625 - val_acc: 0.6809\n",
            "Epoch 135/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0102 - acc: 0.9964 - val_loss: 5.0331 - val_acc: 0.6834\n",
            "Epoch 136/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 5.0306 - val_acc: 0.6876\n",
            "Epoch 137/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 4.9815 - val_acc: 0.6901\n",
            "Epoch 138/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0119 - acc: 0.9960 - val_loss: 5.1108 - val_acc: 0.6809\n",
            "Epoch 139/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0090 - acc: 0.9973 - val_loss: 5.0764 - val_acc: 0.6825\n",
            "Epoch 140/150\n",
            "4788/4788 [==============================] - 60s 12ms/step - loss: 0.0038 - acc: 0.9985 - val_loss: 5.0797 - val_acc: 0.6800\n",
            "Epoch 141/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 5.6364 - val_acc: 0.6399\n",
            "Epoch 142/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0126 - acc: 0.9975 - val_loss: 5.0031 - val_acc: 0.6867\n",
            "Epoch 143/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 5.0668 - val_acc: 0.6850\n",
            "Epoch 144/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 5.0715 - val_acc: 0.6842\n",
            "Epoch 145/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 4.8976 - val_acc: 0.6934\n",
            "Epoch 146/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0142 - acc: 0.9948 - val_loss: 5.0182 - val_acc: 0.6867\n",
            "Epoch 147/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 5.1043 - val_acc: 0.6792\n",
            "Epoch 148/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 5.1258 - val_acc: 0.6809\n",
            "Epoch 149/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0049 - acc: 0.9979 - val_loss: 5.0264 - val_acc: 0.6850\n",
            "Epoch 150/150\n",
            "4788/4788 [==============================] - 60s 13ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.9871 - val_acc: 0.6892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sQCnG7NDPSi2",
        "colab_type": "code",
        "outputId": "22830e5c-a88e-4092-936c-b6f40f431cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['acc'], color='red')\n",
        "ax.plot(hist.history['val_acc'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wElQZ3aMu4pUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f842893f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D4UhfftoPZ7t",
        "colab_type": "code",
        "outputId": "9d29f574-c21d-4597-e03a-86f6160c890e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(hist.history['loss'], color='red')\n",
        "ax.plot(hist.history['val_loss'], color ='green')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFnCAYAAACcvYGMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsJn/B7sRVznQIzpCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f841ad1da90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YUeuBu4oPf7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_nsWEqFPk-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/My Drive/project/model_check_path_BreakHis_40_bin_K_inception_v3_imagenet_transfer_learning')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aj_8wweaPyED",
        "colab_type": "code",
        "outputId": "7cce8687-557d-407e-832d-2f6a79b9dce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_valid)\n",
        "print(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.03      0.06       372\n",
            "           1       0.69      0.99      0.82       825\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      1197\n",
            "   macro avg       0.69      0.51      0.44      1197\n",
            "weighted avg       0.69      0.69      0.58      1197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tQOljWyRP4wT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.grid(b=False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42oGYSIoP_Uz",
        "colab_type": "code",
        "outputId": "af6c3ac7-d9ad-4fcb-ab41-98bee9b6f0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1))\n",
        "plot_confusion_matrix(cm = cm,\n",
        "                      normalize    = False,\n",
        "                      cmap = 'Reds',\n",
        "                      target_names = ['benign','malignant'],\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAG+CAYAAABRbDecAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAK2IAiCICwAImALgiAIwgLwF/l3FG9lQdM0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8418c0ec88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}